% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/visit_probability.R
\name{visit_probability}
\alias{visit_probability}
\title{State Visit Probability}
\usage{
visit_probability(model, pi = NULL, start = NULL, method = "matrix", ...)
}
\arguments{
\item{model}{a solved \link{MDP} object.}

\item{pi}{the used policy. If missing the policy in
\code{model} is used.}

\item{start}{specification of the start distribution. If missing the specification in
\code{model} is used.}

\item{method}{calculate the modified stationary distribution using \code{"matrix"}
(matrix multiplication) or \code{"sample"} (trajectory sampling).}

\item{min_err}{repeats multiplying till the largest difference between
two consecutive vectors is less then \code{min_err}.}
}
\value{
a visit probability vector over all states.
}
\description{
Calculates the state visit probability (the modified stationary distribution)
when following a policy from the start state.
}
\details{
The visit probability is the stationary distribution for the transition matrix
induced by the policy. To account for absorbing states, we modify the
transition matrix by setting all outgoing probabilities from absorbing states
to 0.
\subsection{Matrix method}{

The stationary distribution can be estimated as the sum of multiplying the
start distribution repeatedly with the modified transition matrix
induced by the policy. We stop multiplying when
the largest difference between entries in the two consecutive vectors is
less then the extra parameter:
\itemize{
\item \code{min_err} stop criterion for the power iteration (default: \code{1e-6}).
}

The resulting vector is normalized to probabilities.
}

\subsection{Sample method}{

The stationary distribution is calculated using \code{n} random walks. The state visit
counts are normalized to a probabilities.
Additional parameters are:
\itemize{
\item \code{n} number of random walks (default \code{1000}).
\item \code{horizon} maximal horizon used to stop a random walk if it has
not reached an absorbing state.
}
}
}
\examples{
data("Maze")
Maze

sol <- solve_MDP(Maze)
visit_probability(sol)

# gw_matrix also can calculate the visit_probability.
gw_matrix(sol, what = "visit_probability")

}
\seealso{
Other policy: 
\code{\link{Q_values}()},
\code{\link{action}()},
\code{\link{bellman_update}()},
\code{\link{greedy_action}()},
\code{\link{policy}()},
\code{\link{policy_evaluation}()},
\code{\link{regret}()},
\code{\link{reward}()},
\code{\link{value_function}()}
}
\author{
Michael Hahsler
}
\concept{policy}
