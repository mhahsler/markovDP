% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sample_MDPE.R
\name{sample_MDP.MDPE}
\alias{sample_MDP.MDPE}
\title{Sample Trajectories from an MDPE}
\usage{
\method{sample_MDP}{MDPE}(
  model,
  n,
  start = NULL,
  horizon = NULL,
  epsilon = NULL,
  trajectories = FALSE,
  progress = TRUE,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{model}{an MDPE model.}

\item{n}{number of trajectories.}

\item{start}{start state.}

\item{horizon}{epochs end once an absorbing state is reached or after
the maximal number of epochs specified via \code{horizon}. If \code{NULL} then the
horizon for the model is used.}

\item{epsilon}{the probability of random actions for using an epsilon-greedy policy.
Default for solved models is 0 and for unsolved model 1.}

\item{trajectories}{logical; return the complete trajectories.}

\item{progress}{show a progress bar?}

\item{verbose}{report used parameters}

\item{...}{further arguments are ignored.}
}
\value{
A list with elements:
\itemize{
\item \code{avg_reward}: The average discounted reward.
\item \code{reward}: Reward for each trajectory.
\item \code{trajectories}: A data.frame with the trajectories. Each row
contains the \code{episode} id, the \code{time} step, the state \code{s},
the chosen action \code{a},
the reward \code{r}, and the next state \code{s_prime}. Trajectories are
only returned for \code{trajectories = TRUE}.
}
}
\description{
Sample trajectories through using a MDPE.
}
\examples{
# enable parallel simulation
# doParallel::registerDoParallel()

# Create a simple maze with the layout:
# XXXXXX
# XSX  X  
# X    X
# X  X X
# X  XGX
# XXXXXX

model <- gw_maze_MDPE(
           dim = c(4, 4),
           start = c(1, 1),
           goal = c(4, 4),
           walls = list(c(1, 2), c(3, 3), c(3, 4)),
           discount = 0.95,
           name = "Simple Maze"
       )
model

sim <- sample_MDP(model, horizon = 500, n = 1, 
                   verbose = TRUE, trajectories = TRUE)
sim
}
\seealso{
Other MDPE: 
\code{\link{MDPE}()},
\code{\link{absorbing_states}()},
\code{\link{act}()},
\code{\link{solve_MDP}()},
\code{\link{solve_MDP_APPROX}()}
}
\author{
Michael Hahsler
}
\concept{MDPE}
