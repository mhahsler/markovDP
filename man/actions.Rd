% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/actions.R
\name{actions}
\alias{actions}
\title{Available Actions in a State}
\usage{
actions(x, state)
}
\arguments{
\item{x}{a \link{MDP} object.}

\item{state}{a character vector of length one specifying the state.}
}
\value{
a character vector with the available actions.

a vector with the available actions.
}
\description{
Determine the set of actions available in a state.
}
\details{
Unavailable actions are modeled as actions that have an immediate
reward of \code{-Inf} in the reward function.
}
\examples{
data(Maze)
gridworld_matrix(Maze)

# The the following actions are always available:
Maze$actions

# An action that leaves the grid currently is allowed but does not do 
# anything.
act(Maze, "s(1,1)", "up")

# Make the action unavailable by setting the reward to -Inf
Maze$reward
Maze$reward <- rbind(
    Maze$reward, 
    R_(action = "up", start.state = "s(1,1)", value = - Inf))

# up in s(1,1) now produces a reward of - Inf
act(Maze, "s(1,1)", "up")

# up is unavailable for s(1,1)
actions(Maze, state = "s(1,1)")

# the rest of the border can be added with more entries in the reward 
# function. But since the algorithm learns not to waste moves, the policy
# eventually will not go out of boundary anyway.
}
\seealso{
Other MDP: 
\code{\link{MDP}()},
\code{\link{accessors}},
\code{\link{act}()},
\code{\link{add_policy}()},
\code{\link{gridworld}},
\code{\link{policy_evaluation}()},
\code{\link{q_values}()},
\code{\link{regret}()},
\code{\link{sample_MDP}()},
\code{\link{solve_MDP}()},
\code{\link{transition_graph}()},
\code{\link{unreachable_and_absorbing}},
\code{\link{value_function}()}
}
\author{
Michael Hahsler
}
\concept{MDP}
