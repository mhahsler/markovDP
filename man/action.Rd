% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/action.R
\name{action}
\alias{action}
\alias{action.MDP}
\title{Action Given a Policy}
\usage{
action(model, ...)

\method{action}{MDP}(model, state, epoch = 1, ...)
}
\arguments{
\item{model}{a solved \link{MDP}.}

\item{...}{further parameters are passed on.}

\item{state}{the state.}

\item{epoch}{what epoch of the policy should be used. Use 1 for converged policies.}
}
\value{
The name of the optimal action.
}
\description{
Returns the action given a policy. If the
policy is optimal, then also the action will be optimal.
}
\examples{
data("Maze")
Maze

sol <- solve_MDP(Maze)
policy(sol)

action(sol, state = "s(1,3)")
}
\seealso{
Other policy: 
\code{\link{policy}()},
\code{\link{policy_evaluation}()},
\code{\link{q_values}()},
\code{\link{reward}()},
\code{\link{value_function}()}
}
\author{
Michael Hahsler
}
\concept{policy}
