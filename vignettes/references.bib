
@ARTICLE{Bellman1957,
    author = "Richard Bellman",
     title = "A Markovian Decision Process",
  journal = "Indiana University Mathematics Journal",
    volume = 6,
      year = 1957,
     issue = 4,
     pages = "679--684",
      issn = "0022-2518",
      url = "https://www.jstor.org/stable/24900506"
}

@book{Howard1960,
  address = {Cambridge, MA},
  author = {Howard, R. A.},
  publisher = {MIT Press},
  title = {Dynamic Programming and Markov Processes},
  year = 1960
}

@article{Puterman1978,
  title={Modified Policy Iteration Algorithms for Discounted Markov Decision Problems},
  author={Martin L. Puterman and Moon Chirl Shin},
  journal={Management Science},
  year={1978},
  volume={24},
  pages={1127--1137},
  doi = {10.1287/mnsc.24.11.1127}
}

@ARTICLE{Manne1960,
title = {On the Job-Shop Scheduling Problem},
author = {Manne, Alan},
year = {1960},
journal = {Operations Research},
volume = {8},
number = {2},
pages = {219-223},
doi = {10.1287/opre.8.2.219}
}

@article{Moore1993,
author = {Andrew Moore and C. G. Atkeson},
title = {Prioritized Sweeping: Reinforcement Learning with Less Data and Less Real Time},
journal = {Machine Learning},
year = {1993},
month = {October},
volume = {13},
number = {1},
pages = {103-130},
doi = {10.1007/BF00993104}
}

@article{Watkins1992,
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  doi = {10.1007/BF00992698},
  issn = {1573-0565},
  journal = {Machine Learning},
  month = may,
  number = 3,
  pages = {279--292},
  title = {Q-learning},
  volume = 8,
  year = 1992
}

@article{Sutton1988,
  author = {Sutton, R.},
  journal = {Machine Learning},
  pages = {9--44},
  title = {Learning to predict by the method of temporal differences},
  volume = 3,
  year = 1988,
  url = {https://link.springer.com/article/10.1007/BF00115009}
}


@techreport{Rummery1994,
author = {Rummery, G. and Niranjan, Mahesan},
year = {1994},
month = {11},
number = {Techreport CUED/F-INFENG/TR 166},
title = {On-Line {Q}-Learning Using Connectionist Systems},
institution = {Cambridge University Engineering Department}
}

@article{Singh2000,
  author = {Singh, Satinder and Jaakkola, Tommi S. and Littman, Michael L. and Szepesv√°ri, Csaba},
  doi = {10.1023/A:1007678930559},
  journal = {Machine Learning},
  number = 3,
  pages = {287-308},
  title = {Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms},
  volume = 38,
  year = 2000
}

@book{Russell2020,
  title = {Artificial Intelligence: A Modern Approach (4th Edition)},
  author = {Stuart J. Russell and Peter Norvig},
  year = {2020},
  url = {http://aima.cs.berkeley.edu/},
  publisher = {Pearson},
  isbn = {9781292401133},
}


@book{Sutton1998,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  publisher = {The MIT Press},
  title = {Reinforcement Learning: {A}n Introduction},
  year = 2018,
  url = {http://incompleteideas.net/book/the-book-2nd.html}
}



@Manual{Bates2022,
    title = {Matrix: Sparse and Dense Matrix Classes and Methods},
    author = {Douglas Bates and Martin Maechler and Mikael Jagan},
    year = {2022},
    note = {R package version 1.5-3},
    url = {https://CRAN.R-project.org/package=Matrix},
}

@ARTICLE{hahsler:Kamalzadeh:2021, 
  AUTHOR = {Farzad Kamalzadeh and Vishal Ahuja and Michael Hahsler and Michael E. Bowen},
  TITLE = {An Analytics-Driven Approach For Optimal Individualized Diabetes Screening},
  JOURNAL = {Production and Operations Management},
  YEAR = {2021},
  MONTH = {September},
  VOLUME = {30},
  NUMBER = {9},
  PAGES = {3161--3191},
  doi = {10.1111/poms.13422},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13422},
  ISSN = {1937-5956}
}

@inproceedings{Puterman1994,
  title={Markov Decision Processes: {D}iscrete Stochastic Dynamic Programming},
  author={Martin L. Puterman},
  booktitle={Wiley Series in Probability and Statistics},
  year={1994}
}

@Manual{Proellochs2020,
    title = {ReinforcementLearning: {M}odel-Free Reinforcement Learning},
    author = {Nicolas Proellochs and Stefan Feuerriegel},
    year = {2020},
    note = {{R} package version 1.0.5},
    url = {https://CRAN.R-project.org/package=ReinforcementLearning},
}

@Manual{R2022,
    title = {R: {A} Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2022},
    url = {https://www.R-project.org/},
}

@Article{igraph2006,
    title = {The igraph software package for complex network research},
    author = {Gabor Csardi and Tamas Nepusz},
    journal = {InterJournal},
    volume = {Complex Systems},
    pages = {1695},
    year = {2006},
    url = {https://igraph.org},
}

@article{Jacomy2014,
  title = {ForceAtlas2, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the {G}ephi Software},
  author = {Jacomy, Mathieu and Venturini, Tommaso and Heymann, Sebastien and Bastian, Mathieu},
  doi = {10.1371/journal.pone.0098679},
  journal = {PLOS ONE},
  month = {06},
  number = 6,
  pages = {1-12},
  publisher = {Public Library of Science},
  volume = 9,
  year = 2014
}

@article{Hauskrecht2000,
author = {Hauskrecht, Milos},
doi = {https://doi.org/10.1613/jair.678},
journal = {Journal Of Artificial Intelligence Research},
pages = {33--94},
title = {Value-Function Approximations for {POMDPs}},
volume = {13},
year = {2000}
}

@phdthesis{Cassandra1998c,
author = {Cassandra, Anthony Rocco},
advisor = {Kaelbling, Leslie Pack},
title = {Exact and Approximate Algorithms for Partially Observable {M}arkov Decision Processes},
year = {1998},
isbn = {0591833220},
publisher = {Brown University},
address = {USA}
}

@Book{Eddelbuettel2013,
  title = {Seamless {R} and {C++} Integration with {Rcpp}},
  author = {Dirk Eddelbuettel},
  publisher = {Springer},
  address = {New York},
  year = {2013},
  note = {ISBN 978-1-4614-6867-7},
  doi = {10.1007/978-1-4614-6868-4},
}

@Manual{Microsoft2022,
    title = {foreach: Provides Foreach Looping Construct},
    author = {{Microsoft} and Steve Weston},
    year = {2022},
    note = {R package version 1.5.2},
    url = {https://CRAN.R-project.org/package=foreach},
}

@Manual{Almende2022,
    title = {visNetwork: Network Visualization using 'vis.js' Library},
    author = {{Almende B.V. and Contributors} and Benoit Thieurmel},
    year = {2022},
    note = {R package version 2.1.2},
    url = {https://CRAN.R-project.org/package=visNetwork},
}

@Book{Wickham2016,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
}

@Manual{Hahsler2024,
    title = {pomdp: Infrastructure for Partially Observable Markov Decision
Processes (POMDP)},
    author = {Michael Hahsler},
    year = {2024},
    note = {R package version 1.2.3},
    url = {https://github.com/mhahsler/pomdp},
  }

@Manual{Hahsler2023,
    title = {pomdpSolve: Interface to 'pomdp-solve' for Partially Observable Markov Decision Processes},
    author = {Michael Hahsler and Anthony R. Cassandra},
    year = {2023},
    note = {R package version 1.0.4},
    url = {https://github.com/mhahsler/pomdpSolve},
}
  
@Manual{CRAN_MDPtoolbox,
    title = {MDPtoolbox: Markov Decision Processes Toolbox},
    author = {Iadine Chades and Guillaume Chapron and Marie-Josee Cros and Frederick Garcia and Regis Sabbadin},
    year = {2017},
    doi = {10.32614/CRAN.package.MDPtoolbox},
    note = {R package version 4.0.3},
    url = {https://CRAN.R-project.org/package=MDPtoolbox},
}

@Manual{CRAN_pomdp,
  title = {pomdp: Infrastructure for Partially Observable Markov Decision Processes (POMDP)},
  author = {Michael Hahsler},
  year = {2024},
  note = {R package version 1.2.3},
  doi = {10.32614/CRAN.package.pomdp},
  url = {https://github.com/mhahsler/pomdp},
}
  
@Manual{CRAN_markovDP,
 title = {markovDP: Infrastructure for Discrete-Time Markov Decision Processes (MDP)},
 author = {Michael Hahsler},
 year = {2024},
 note = {R package version 0.99.0},
 url = {https://github.com/mhahsler/markovDP},
}